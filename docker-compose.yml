services:

  web:
    build: .
    ports:
      - "8000:8000"


  db:
    image: postgres:17.2
    restart: always
    # set shared memory limit when using docker-compose
    shm_size: 128mb
    # or set shared memory limit when deploy via swarm stack
    #volumes:
    #  - type: tmpfs
    #    target: /dev/shm
    #    tmpfs:
    #      size: 134217728 # 128*2^20 bytes = 128Mb
    ports:
      - '5432:5432'
    env_file: .db.local.env
#
#  cache:
#    image: redis:8.0-M02-alpine
#    restart: always
#    ports:
#      - '6379:6379'
#
#  rabbitmq:
#    image: rabbitmq:4-management
#    ports:
#      - "5672:5672"
#      - "15672:15672"
#
#  zookeeper:
#    platform: linux
#    image: confluentinc/cp-zookeeper:7.3.2
#    ports:
#      - "2181:2181"
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#      ZOOKEEPER_SERVER_ID: 1
#      ZOOKEEPER_SERVERS: zoo1:2888:3888
#
#  kafka:
#    platform: linux
#    image: confluentinc/cp-kafka:7.3.2
#
#    ports:
#      - "9092:9092"
#      - "29092:29092"
#      - "9999:9999"
#    environment:
#      KAFKA_LISTENERS: INTERNAL://0.0.0.0:19092,EXTERNAL://0.0.0.0:9092,DOCKER://0.0.0.0:29092
#      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:19092,EXTERNAL://localhost:9092,DOCKER://host.docker.internal:29092
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
#      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
#      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
#      KAFKA_BROKER_ID: 1
#      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
#      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#      KAFKA_JMX_PORT: 9999
#      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
#      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
#      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
#    depends_on:
#      - zookeeper
#
#  schemaregistry:
#    platform: linux
#    image: pravega/schemaregistry
#    restart: always
#    depends_on:
#      - zookeeper
#    environment:
#      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"
#      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
#      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8085"
#    ports:
#      - "18085:8085"
#
#  kafdrop:
#    platform: linux
#    image: obsidiandynamics/kafdrop:3.31.0-SNAPSHOT
#    depends_on:
#      - kafka
#      - schemaregistry
#    ports:
#      - "19000:9000"
#    environment:
#      KAFKA_BROKERCONNECT: kafka:19092
#      CMD_ARGS: "--message.format=AVRO --message.keyFormat=DEFAULT --schemaregistry.connect=http://schemaregistry:8085"
#
#
#
#volumes:
#  zookeeper_data:
#    driver: local
#  kafka_data:
#    driver: local
#
#
#

#  prometheus:
#    image: prom/prometheus
#    command:
#      - "--config.file=/code/prometheus_config.yml"
#    ports:
#      - "9090:9090"
#    restart: unless-stopped
#    volumes:
#      - ./etc/prometheus_config.yml:/code/prometheus_config.yml


#  grafana:
#    image: grafana/grafana-enterprise
#    restart: unless-stopped
#    ports:
#      - '3000:3000'
#    volumes:
#      - ./etc/grafana.ini:/code/grafana.ini
#    command: [ '--config', '/code/grafana.ini' ]